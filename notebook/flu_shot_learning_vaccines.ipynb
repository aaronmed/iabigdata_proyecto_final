{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PROYECTO FINAL</h1>\n",
    "\n",
    "![badge](author-badge.svg)\n",
    "\n",
    "<div>\n",
    "    <img src=\"vaccine.jpg\"/>\n",
    "</div>\n",
    "\n",
    "<h2>Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.drivendata.org/competitions/66/flu-shot-learning/page/210/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puedes predecir si las personas se pusieron las vacunas contra la H1N1 y la gripe estacional usando la información que compartieron sobre sus antecedentes, opiniones y comportamientos de salud?\n",
    "\n",
    "En este desafío, veremos la vacunación, una medida clave de salud pública para combatir enfermedades infecciosas. Las vacunas proporcionan inmunización a los individuos, y suficiente inmunización en una comunidad puede reducir aún más la propagación de enfermedades a través de la \"inmunidad de grupo.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al momento del lanzamiento de esta competencia, las vacunas para el virus del COVID-19 todavía están en desarrollo y no están disponibles. En cambio, la competencia revisará la respuesta de salud pública a una pandemia respiratoria importante y reciente. A partir de la primavera de 2009, una pandemia causada por el virus de la influenza H1N1, conocido coloquialmente como \"gripe porcina,\" se extendió por todo el mundo. Los investigadores estiman que en el primer año fue responsable de entre 151,000 y 575,000 muertes a nivel global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, auc, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from lazypredict import LazyClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos el PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path = \"results.pdf\"\n",
    "# c = canvas.Canvas(pdf_path, pagesize=letter)\n",
    "# width, height = letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interfaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values():\n",
    "    global use_moda_train, delete_null_values_train, use_knn_imputer_train\n",
    "    global use_moda_test, use_knn_imputer_test\n",
    "    global num_neighbors_knn, number_of_best_features\n",
    "    global use_logistic_regression_h1n1_vaccine, use_random_forest_h1n1_vaccine, use_ada_boost_classifier_h1n1_vaccine, use_xgb_classifier_h1n1_vaccine, use_red_neuronal_h1n1_vaccine\n",
    "    global use_logistic_regression_seasonal_vaccine, use_random_forest_seasonal_vaccine, use_ada_boost_classifier_seasonal_vaccine, use_xgb_classifier_seasonal_vaccine, use_red_neuronal_seasonal_vaccine\n",
    "    global epochs_red_neuronal, use_grid_search, use_random_search\n",
    "    global use_standard_scaler, use_minmax_scaler, not_use_scaler\n",
    "    global use_smote, use_adasyn, use_nearmiss, not_use_balanced\n",
    "\n",
    "    use_moda_train = bool_var_use_moda_train.get()\n",
    "    delete_null_values_train = bool_var_delete_null_values_train.get()\n",
    "    use_knn_imputer_train = bool_var_use_knn_imputer_train.get()\n",
    "    use_moda_test = bool_var_use_moda_test.get()\n",
    "    use_knn_imputer_test = bool_var_use_knn_imputer_test.get()\n",
    "    \n",
    "    try:\n",
    "        num_neighbors_knn = int(entry_num_neighbors_knn.get())\n",
    "        if num_neighbors_knn < 1 or num_neighbors_knn > 20:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Error\", \"El número de vecinos debe estar entre 1 y 20\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        number_of_best_features = int(entry_number_of_best_features.get())\n",
    "        if number_of_best_features < 1 or number_of_best_features > 20:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Error\", \"El número de mejores características debe estar entre 1 y 20\")\n",
    "        return\n",
    "\n",
    "    use_logistic_regression_h1n1_vaccine = bool_var_use_logistic_regression_h1n1_vaccine.get()\n",
    "    use_random_forest_h1n1_vaccine = bool_var_use_random_forest_h1n1_vaccine.get()\n",
    "    use_ada_boost_classifier_h1n1_vaccine = bool_var_use_ada_boost_classifier_h1n1_vaccine.get()\n",
    "    use_xgb_classifier_h1n1_vaccine = bool_var_use_xgb_classifier_h1n1_vaccine.get()\n",
    "    use_red_neuronal_h1n1_vaccine = bool_var_use_red_neuronal_h1n1_vaccine.get()\n",
    "\n",
    "    use_logistic_regression_seasonal_vaccine = bool_var_use_logistic_regression_seasonal_vaccine.get()\n",
    "    use_random_forest_seasonal_vaccine = bool_var_use_random_forest_seasonal_vaccine.get()\n",
    "    use_ada_boost_classifier_seasonal_vaccine = bool_var_use_ada_boost_classifier_seasonal_vaccine.get()\n",
    "    use_xgb_classifier_seasonal_vaccine = bool_var_use_xgb_classifier_seasonal_vaccine.get()\n",
    "    use_red_neuronal_seasonal_vaccine = bool_var_use_red_neuronal_seasonal_vaccine.get()\n",
    "    \n",
    "    try:\n",
    "        epochs_red_neuronal = int(entry_epochs_red_neuronal.get())\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Error\", \"El número de épocas debe ser un número entero\")\n",
    "        return\n",
    "\n",
    "    use_grid_search = bool_var_use_grid_search.get()\n",
    "    use_random_search = bool_var_use_random_search.get()\n",
    "    use_standard_scaler = bool_var_use_standard_scaler.get()\n",
    "    use_minmax_scaler = bool_var_use_minmax_scaler.get()\n",
    "    not_use_scaler = bool_var_not_use_scaler.get()\n",
    "    use_smote = bool_var_use_smote.get()\n",
    "    use_adasyn = bool_var_use_adasyn.get()\n",
    "    use_nearmiss = bool_var_use_nearmiss.get()\n",
    "    not_use_balanced = bool_var_not_use_balanced.get()\n",
    "    \n",
    "    print(\"use_moda_train:\", use_moda_train)\n",
    "    print(\"delete_null_values_train:\", delete_null_values_train)\n",
    "    print(\"use_knn_imputer_train:\", use_knn_imputer_train)\n",
    "    print(\"use_moda_test:\", use_moda_test)\n",
    "    print(\"use_knn_imputer_test:\", use_knn_imputer_test)\n",
    "    print(\"num_neighbors_knn:\", num_neighbors_knn)\n",
    "    print(\"number_of_best_features:\", number_of_best_features)\n",
    "    print(\"use_logistic_regression_h1n1_vaccine:\", use_logistic_regression_h1n1_vaccine)\n",
    "    print(\"use_random_forest_h1n1_vaccine:\", use_random_forest_h1n1_vaccine)\n",
    "    print(\"use_ada_boost_classifier_h1n1_vaccine:\", use_ada_boost_classifier_h1n1_vaccine)\n",
    "    print(\"use_xgb_classifier_h1n1_vaccine:\", use_xgb_classifier_h1n1_vaccine)\n",
    "    print(\"use_red_neuronal_h1n1_vaccine:\", use_red_neuronal_h1n1_vaccine)\n",
    "    print(\"use_logistic_regression_seasonal_vaccine:\", use_logistic_regression_seasonal_vaccine)\n",
    "    print(\"use_random_forest_seasonal_vaccine:\", use_random_forest_seasonal_vaccine)\n",
    "    print(\"use_ada_boost_classifier_seasonal_vaccine:\", use_ada_boost_classifier_seasonal_vaccine)\n",
    "    print(\"use_xgb_classifier_seasonal_vaccine:\", use_xgb_classifier_seasonal_vaccine)\n",
    "    print(\"use_red_neuronal_seasonal_vaccine:\", use_red_neuronal_seasonal_vaccine)\n",
    "    print(\"epochs_red_neuronal:\", epochs_red_neuronal)\n",
    "    print(\"use_grid_search:\", use_grid_search)\n",
    "    print(\"use_random_search:\", use_random_search)\n",
    "    print(\"use_standard_scaler:\", use_standard_scaler)\n",
    "    print(\"use_minmax_scaler:\", use_minmax_scaler)\n",
    "    print(\"not_use_scaler:\", not_use_scaler)\n",
    "    print(\"use_smote:\", use_smote)\n",
    "    print(\"use_adasyn:\", use_adasyn)\n",
    "    print(\"use_nearmiss:\", use_nearmiss)\n",
    "    print(\"not_use_balanced:\", not_use_balanced)\n",
    "    \n",
    "    root.destroy()\n",
    "\n",
    "# Initialize main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Configuración de Variables\")\n",
    "\n",
    "# Variables\n",
    "bool_var_use_moda_train = tk.BooleanVar(value=False)\n",
    "bool_var_delete_null_values_train = tk.BooleanVar(value=False)\n",
    "bool_var_use_knn_imputer_train = tk.BooleanVar(value=True)\n",
    "bool_var_use_moda_test = tk.BooleanVar(value=False)\n",
    "bool_var_use_knn_imputer_test = tk.BooleanVar(value=True)\n",
    "bool_var_use_logistic_regression_h1n1_vaccine = tk.BooleanVar(value=True)\n",
    "bool_var_use_random_forest_h1n1_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_ada_boost_classifier_h1n1_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_xgb_classifier_h1n1_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_red_neuronal_h1n1_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_logistic_regression_seasonal_vaccine = tk.BooleanVar(value=True)\n",
    "bool_var_use_random_forest_seasonal_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_ada_boost_classifier_seasonal_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_xgb_classifier_seasonal_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_red_neuronal_seasonal_vaccine = tk.BooleanVar(value=False)\n",
    "bool_var_use_grid_search = tk.BooleanVar(value=True)\n",
    "bool_var_use_random_search = tk.BooleanVar(value=False)\n",
    "bool_var_use_standard_scaler = tk.BooleanVar(value=False)\n",
    "bool_var_use_minmax_scaler = tk.BooleanVar(value=False)\n",
    "bool_var_not_use_scaler = tk.BooleanVar(value=True)\n",
    "bool_var_use_smote = tk.BooleanVar(value=False)\n",
    "bool_var_use_adasyn = tk.BooleanVar(value=False)\n",
    "bool_var_use_nearmiss = tk.BooleanVar(value=False)\n",
    "bool_var_not_use_balanced = tk.BooleanVar(value=True)\n",
    "\n",
    "# Functions to ensure only one selection per group\n",
    "def disable_other_null_value_methods_train():\n",
    "    bool_var_delete_null_values_train.set(False)\n",
    "    bool_var_use_knn_imputer_train.set(False)\n",
    "\n",
    "def disable_other_null_value_methods_knn_train():\n",
    "    bool_var_use_moda_train.set(False)\n",
    "    bool_var_delete_null_values_train.set(False)\n",
    "\n",
    "def disable_other_null_value_methods_delete_train():\n",
    "    bool_var_use_moda_train.set(False)\n",
    "    bool_var_use_knn_imputer_train.set(False)\n",
    "\n",
    "def disable_other_null_value_methods_test():\n",
    "    bool_var_use_knn_imputer_test.set(False)\n",
    "\n",
    "def disable_other_null_value_methods_knn_test():\n",
    "    bool_var_use_moda_test.set(False)\n",
    "\n",
    "def disable_other_models_h1n1():\n",
    "    bool_var_use_random_forest_h1n1_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_h1n1_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_h1n1_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_h1n1_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_rf_h1n1():\n",
    "    bool_var_use_logistic_regression_h1n1_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_h1n1_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_h1n1_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_h1n1_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_ada_h1n1():\n",
    "    bool_var_use_logistic_regression_h1n1_vaccine.set(False)\n",
    "    bool_var_use_random_forest_h1n1_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_h1n1_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_h1n1_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_nn_h1n1():\n",
    "    bool_var_use_logistic_regression_h1n1_vaccine.set(False)\n",
    "    bool_var_use_random_forest_h1n1_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_h1n1_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_h1n1_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_xgb_h1n1():\n",
    "    bool_var_use_logistic_regression_h1n1_vaccine.set(False)\n",
    "    bool_var_use_random_forest_h1n1_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_h1n1_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_h1n1_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_seasonal():\n",
    "    bool_var_use_random_forest_seasonal_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_seasonal_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_seasonal_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_seasonal_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_rf_seasonal():\n",
    "    bool_var_use_logistic_regression_seasonal_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_seasonal_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_seasonal_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_seasonal_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_ada_seasonal():\n",
    "    bool_var_use_logistic_regression_seasonal_vaccine.set(False)\n",
    "    bool_var_use_random_forest_seasonal_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_seasonal_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_seasonal_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_nn_seasonal():\n",
    "    bool_var_use_logistic_regression_seasonal_vaccine.set(False)\n",
    "    bool_var_use_random_forest_seasonal_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_seasonal_vaccine.set(False)\n",
    "    bool_var_use_xgb_classifier_seasonal_vaccine.set(False)\n",
    "\n",
    "def disable_other_models_xgb_seasonal():\n",
    "    bool_var_use_logistic_regression_seasonal_vaccine.set(False)\n",
    "    bool_var_use_random_forest_seasonal_vaccine.set(False)\n",
    "    bool_var_use_red_neuronal_seasonal_vaccine.set(False)\n",
    "    bool_var_use_ada_boost_classifier_seasonal_vaccine.set(False)\n",
    "\n",
    "def disable_other_search_methods():\n",
    "    bool_var_use_random_search.set(False)\n",
    "\n",
    "def disable_other_search_methods_random():\n",
    "    bool_var_use_grid_search.set(False)\n",
    "\n",
    "def disable_other_scalers():\n",
    "    bool_var_use_standard_scaler.set(False)\n",
    "    bool_var_not_use_scaler.set(False)\n",
    "\n",
    "def disable_other_scalers_standard():\n",
    "    bool_var_use_minmax_scaler.set(False)\n",
    "    bool_var_not_use_scaler.set(False)\n",
    "\n",
    "def disable_other_scalers_not():\n",
    "    bool_var_use_minmax_scaler.set(False)\n",
    "    bool_var_use_standard_scaler.set(False)\n",
    "\n",
    "def disable_other_balancing_methods():\n",
    "    bool_var_use_adasyn.set(False)\n",
    "    bool_var_use_nearmiss.set(False)\n",
    "    bool_var_not_use_balanced.set(False)\n",
    "\n",
    "def disable_other_balancing_methods_adasyn():\n",
    "    bool_var_use_smote.set(False)\n",
    "    bool_var_use_nearmiss.set(False)\n",
    "    bool_var_not_use_balanced.set(False)\n",
    "\n",
    "def disable_other_balancing_methods_nearmiss():\n",
    "    bool_var_use_smote.set(False)\n",
    "    bool_var_use_adasyn.set(False)\n",
    "    bool_var_not_use_balanced.set(False)\n",
    "\n",
    "def disable_other_balancing_methods_not():\n",
    "    bool_var_use_smote.set(False)\n",
    "    bool_var_use_adasyn.set(False)\n",
    "    bool_var_use_nearmiss.set(False)\n",
    "\n",
    "# Layout with added padding\n",
    "pad_options = {'padx': 5, 'pady': 5}\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué proceso seguir para rellenar los valores nulos de los datos de entrenamiento?\").grid(column=0, row=0, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Usar Moda\", variable=bool_var_use_moda_train, command=disable_other_null_value_methods_train).grid(column=1, row=0, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Eliminar valores nulos\", variable=bool_var_delete_null_values_train, command=disable_other_null_value_methods_delete_train).grid(column=2, row=0, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Usar KNNImputer\", variable=bool_var_use_knn_imputer_train, command=disable_other_null_value_methods_knn_train).grid(column=3, row=0, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué proceso seguir para rellenar los valores nulos de los datos de test?\").grid(column=0, row=1, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Usar Moda\", variable=bool_var_use_moda_test, command=disable_other_null_value_methods_test).grid(column=1, row=1, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Usar KNNImputer\", variable=bool_var_use_knn_imputer_test, command=disable_other_null_value_methods_knn_test).grid(column=2, row=1, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"Número de vecinos para KNNImputer (1-20)\").grid(column=0, row=2, sticky=tk.W, **pad_options)\n",
    "entry_num_neighbors_knn = ttk.Entry(root)\n",
    "entry_num_neighbors_knn.insert(0, \"5\")\n",
    "entry_num_neighbors_knn.grid(column=1, row=2, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Con cuántas variables te quedas para el entrenamiento? (1-20)\").grid(column=0, row=3, sticky=tk.W, **pad_options)\n",
    "entry_number_of_best_features = ttk.Entry(root)\n",
    "entry_number_of_best_features.insert(0, \"10\")\n",
    "entry_number_of_best_features.grid(column=1, row=3, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué modelo eliges para entrenar h1n1_vaccine?\").grid(column=0, row=4, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"LogisticRegression\", variable=bool_var_use_logistic_regression_h1n1_vaccine, command=disable_other_models_h1n1).grid(column=1, row=4, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"RandomForestClassifier\", variable=bool_var_use_random_forest_h1n1_vaccine, command=disable_other_models_rf_h1n1).grid(column=2, row=4, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"AdaBoostClassifier\", variable=bool_var_use_ada_boost_classifier_h1n1_vaccine, command=disable_other_models_ada_h1n1).grid(column=3, row=4, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"XGBClassifier\", variable=bool_var_use_xgb_classifier_h1n1_vaccine, command=disable_other_models_xgb_h1n1).grid(column=4, row=4, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Red Neuronal\", variable=bool_var_use_red_neuronal_h1n1_vaccine, command=disable_other_models_nn_h1n1).grid(column=5, row=4, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué modelo eliges para entrenar seasonal_vaccine?\").grid(column=0, row=5, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"LogisticRegression\", variable=bool_var_use_logistic_regression_seasonal_vaccine, command=disable_other_models_seasonal).grid(column=1, row=5, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"RandomForestClassifier\", variable=bool_var_use_random_forest_seasonal_vaccine, command=disable_other_models_rf_seasonal).grid(column=2, row=5, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"AdaBoostClassifier\", variable=bool_var_use_ada_boost_classifier_seasonal_vaccine, command=disable_other_models_ada_seasonal).grid(column=3, row=5, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"XGBClassifier\", variable=bool_var_use_xgb_classifier_seasonal_vaccine, command=disable_other_models_xgb_seasonal).grid(column=4, row=5, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Red Neuronal\", variable=bool_var_use_red_neuronal_seasonal_vaccine, command=disable_other_models_nn_seasonal).grid(column=5, row=5, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"Si se ha seleccionado red neuronal, ¿cuántas épocas?\").grid(column=0, row=6, sticky=tk.W, **pad_options)\n",
    "entry_epochs_red_neuronal = ttk.Entry(root)\n",
    "entry_epochs_red_neuronal.insert(0, \"20\")\n",
    "entry_epochs_red_neuronal.grid(column=1, row=6, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué tipo de búsqueda de hiperpárametros? (si no ha elegido red neuronal)\").grid(column=0, row=7, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Grid Search\", variable=bool_var_use_grid_search, command=disable_other_search_methods).grid(column=1, row=7, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Random Search\", variable=bool_var_use_random_search, command=disable_other_search_methods_random).grid(column=2, row=7, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué tipo de escalamiento de datos?\").grid(column=0, row=8, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"Standard Scaler\", variable=bool_var_use_standard_scaler, command=disable_other_scalers_standard).grid(column=1, row=8, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"MinMax Scaler\", variable=bool_var_use_minmax_scaler, command=disable_other_scalers).grid(column=2, row=8, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"No usar escalamiento\", variable=bool_var_not_use_scaler, command=disable_other_scalers_not).grid(column=3, row=8, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Label(root, text=\"¿Qué tipo de balanceo de datos para clases minoritarias?\").grid(column=0, row=9, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"SMOTE\", variable=bool_var_use_smote, command=disable_other_balancing_methods).grid(column=1, row=9, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"ADASYN\", variable=bool_var_use_adasyn, command=disable_other_balancing_methods_adasyn).grid(column=2, row=9, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"NearMiss\", variable=bool_var_use_nearmiss, command=disable_other_balancing_methods_nearmiss).grid(column=3, row=9, sticky=tk.W, **pad_options)\n",
    "ttk.Checkbutton(root, text=\"No usar balanceo\", variable=bool_var_not_use_balanced, command=disable_other_balancing_methods_not).grid(column=4, row=9, sticky=tk.W, **pad_options)\n",
    "\n",
    "ttk.Button(root, text=\"Entrenar\", command=update_values).grid(column=0, row=10, sticky=tk.W, **pad_options)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de entrenamiento con las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/aaronmed/iabigdata_proyecto_final/main/dataset/training_set_features.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de entrenamiento con las variables objetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels = pd.read_csv('https://raw.githubusercontent.com/aaronmed/iabigdata_proyecto_final/main/dataset/training_set_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos ambos dataset por la columna identificadora (el id del encuestado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_training_labels, on='respondent_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('https://raw.githubusercontent.com/aaronmed/iabigdata_proyecto_final/main/dataset/test_set_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos los valores únicos que existen con el objetivo de ver si son características categóricas o numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos = merged_df.select_dtypes(include=['object']).apply(pd.Series.nunique)\n",
    "\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos cuáles son los valores de las columnas de tipo objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in merged_df.select_dtypes(include=['object']):\n",
    "    print(columna, \":\", df[columna].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_h1n1_vaccine = ['#D18C7F', '#85CAA0']\n",
    "palette_seasonal_vaccine = ['#e74c3c', '#2ecc71']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in merged_df.select_dtypes(include=['object']).columns:\n",
    "    # Obtenemos las frecuencias de los valores\n",
    "    value_counts = merged_df[col].value_counts()\n",
    "    \n",
    "    # Creamos el gráfico de barras\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    value_counts.plot(kind='bar')\n",
    "    plt.title(f'Frecuencia de valores en {col}')\n",
    "    plt.xlabel('Valores')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Mostramos el gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='age_group', hue='h1n1_vaccine', data=merged_df, palette=palette_h1n1_vaccine)\n",
    "plt.title('Distribución de age_group vs. h1n1_vaccine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='age_group', hue='seasonal_vaccine', data=merged_df, palette=palette_seasonal_vaccine)\n",
    "plt.title('Distribución de age_group vs. seasonal_vaccine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "merged_df['race'].value_counts().plot.pie(autopct='%1.1f%%')\n",
    "plt.title('Proporción de categorías en race')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_no_vaccine = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "colors_vaccine = ['#c2c2f0','#ffb3e6','#c4e17f','#ff6666']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "merged_df[merged_df['h1n1_vaccine'] == 0]['race'].value_counts().plot.pie(ax=ax[0], autopct='%1.1f%%', startangle=90, colors=colors_no_vaccine)\n",
    "ax[0].set_title('Proporción de race (No h1n1_vaccine)')\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "merged_df[merged_df['h1n1_vaccine'] == 1]['race'].value_counts().plot.pie(ax=ax[1], autopct='%1.1f%%', startangle=90, colors=colors_vaccine)\n",
    "ax[1].set_title('Proporción de race (Sí h1n1_vaccine)')\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "merged_df[merged_df['seasonal_vaccine'] == 0]['race'].value_counts().plot.pie(ax=ax[0], autopct='%1.1f%%', startangle=90, colors=colors_no_vaccine)\n",
    "ax[0].set_title('Proporción de race (No seasonal_vaccine)')\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "merged_df[merged_df['seasonal_vaccine'] == 1]['race'].value_counts().plot.pie(ax=ax[1], autopct='%1.1f%%', startangle=90, colors=colors_vaccine)\n",
    "ax[1].set_title('Proporción de race (Sí seasonal_vaccine)')\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = [col for col in merged_df.columns if merged_df[col].dropna().unique().tolist() in ([0, 1], [1, 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de columnas por fila\n",
    "cols_per_row = 3\n",
    "\n",
    "# Número total de gráficas\n",
    "total_plots = len(binary_columns)\n",
    "\n",
    "# Número de filas necesarias\n",
    "num_figures = math.ceil(total_plots / cols_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar las figuras necesarias\n",
    "for fig_num in range(num_figures):\n",
    "    # Crear una nueva figura\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Determinar el rango de columnas para esta figura\n",
    "    start_idx = fig_num * cols_per_row\n",
    "    end_idx = min(start_idx + cols_per_row, total_plots)\n",
    "    \n",
    "    for i, col in enumerate(binary_columns[start_idx:end_idx]):\n",
    "        plt.subplot(1, cols_per_row, i+1)\n",
    "        sns.countplot(x=col, hue='h1n1_vaccine', data=merged_df, palette=palette_h1n1_vaccine)\n",
    "        plt.title(f'{col} vs. h1n1_vaccine')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar las figuras necesarias\n",
    "for fig_num in range(num_figures):\n",
    "    # Crear una nueva figura\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Determinar el rango de columnas para esta figura\n",
    "    start_idx = fig_num * cols_per_row\n",
    "    end_idx = min(start_idx + cols_per_row, total_plots)\n",
    "    \n",
    "    for i, col in enumerate(binary_columns[start_idx:end_idx]):\n",
    "        plt.subplot(1, cols_per_row, i+1)\n",
    "        sns.countplot(x=col, hue='seasonal_vaccine', data=merged_df, palette=palette_seasonal_vaccine)\n",
    "        plt.title(f'{col} vs. seasonal_vaccine')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='income_poverty', hue='h1n1_vaccine', data=merged_df, palette=palette_h1n1_vaccine)\n",
    "plt.title('Income Poverty vs. H1N1 Vaccine')\n",
    "plt.xlabel('Income Poverty')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='H1N1 Vaccine', loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='income_poverty', hue='seasonal_vaccine', data=merged_df, palette=palette_seasonal_vaccine)\n",
    "plt.title('Income Poverty vs. Seasonal Vaccine')\n",
    "plt.xlabel('Income Poverty')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Seasonal Vaccine', loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_sweetviz_h1n1_vaccine = False\n",
    "view_sweetviz_seasonal_vaccine = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if view_sweetviz_h1n1_vaccine:\n",
    "    report_h1n1_vaccine = sv.analyze(merged_df, target_feat='h1n1_vaccine')\n",
    "\n",
    "    report_h1n1_vaccine.show_notebook(layout=\"widescreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if view_sweetviz_seasonal_vaccine:\n",
    "    report_seasonal_vaccine = sv.analyze(merged_df, target_feat='seasonal_vaccine')\n",
    "\n",
    "    report_seasonal_vaccine.show_notebook(layout=\"widescreen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para etiquetar los valores de los gráficos de tarta\n",
    "def label_function(val):\n",
    "    return 'Vacunado' if val == 1 else 'No vacunado'\n",
    "\n",
    "# Contamos la cantidad de vacunados (valor 1) y no vacunados (valor 0) para cada vacuna\n",
    "h1n1_counts = merged_df['h1n1_vaccine'].value_counts()\n",
    "seasonal_counts = merged_df['seasonal_vaccine'].value_counts()\n",
    "\n",
    "# Creamos el primer gráfico de tarta para h1n1_vaccine\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(h1n1_counts, labels=h1n1_counts.index.map(label_function), autopct='%1.1f%%', startangle=140, colors=palette_h1n1_vaccine)\n",
    "plt.title('Proporción vacunados de la gripe H1N1')\n",
    "plt.axis('equal')\n",
    "\n",
    "# Creamos el segundo gráfico de tarta para seasonal_vaccine\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(seasonal_counts, labels=seasonal_counts.index.map(label_function), autopct='%1.1f%%', startangle=140, colors=palette_seasonal_vaccine)\n",
    "plt.title('Proporción de vacunados de la gripe estacional')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversión de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_label_encoder = pd.concat([merged_df, test])\n",
    "\n",
    "categorical_columns = df_for_label_encoder.select_dtypes(include=['object'])\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_columns.columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit_transform(df_for_label_encoder[col])\n",
    "    encoders[col] = le \n",
    "    \n",
    "for col, le in encoders.items():\n",
    "    merged_df[col] = le.transform(merged_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns.columns:\n",
    "    print(col)\n",
    "    \n",
    "for col in categorical_columns.columns:\n",
    "    print(encoders[col].classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = merged_df.corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = merged_df.corr()\n",
    "\n",
    "limit_filtered_correlation_matrix = 0.20\n",
    "\n",
    "filtered_corr_matrix = correlation_matrix[(np.abs(correlation_matrix) > limit_filtered_correlation_matrix) & (correlation_matrix != 1.0)]\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(filtered_corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(f'Matriz de correlación (Valores absolutos > {limit_filtered_correlation_matrix})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráficas de visualización para análisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = merged_df.groupby(['h1n1_vaccine', 'doctor_recc_h1n1']).size().reset_index(name='count')\n",
    "\n",
    "# Crear una columna combinada para usar como etiquetas en el eje x\n",
    "combinations['combination'] = combinations.apply(\n",
    "    lambda row: f\"V: {'Sí' if row['h1n1_vaccine'] == 1 else 'No'} y R: {'Sí' if row['doctor_recc_h1n1'] == 1 else 'No'}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Crear un gráfico de barras con tamaño ajustado\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "combinations.plot(kind='bar', x='combination', y='count', ax=ax, legend=False, color='salmon')\n",
    "\n",
    "# Etiquetas y título del gráfico\n",
    "ax.set_xlabel('Combinaciones de Vacunación para el H1N1 y Recomendación')\n",
    "ax.set_ylabel('Número de Encuestados')\n",
    "ax.set_title('Número de Encuestados por Combinaciones de h1n1_vaccine y doctor_recc_h1n1')\n",
    "\n",
    "# Colocar los labels en diagonal con ajuste de alineación y tamaño de fuente\n",
    "plt.xticks(rotation=0, ha='center', fontsize=10)\n",
    "\n",
    "# Ajustar el diseño para que las etiquetas no se corten\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = merged_df.groupby(['seasonal_vaccine', 'doctor_recc_seasonal']).size().reset_index(name='count')\n",
    "\n",
    "# Crear una columna combinada para usar como etiquetas en el eje x\n",
    "combinations['combination'] = combinations.apply(\n",
    "    lambda row: f\"V: {'Sí' if row['seasonal_vaccine'] == 1 else 'No'} y R: {'Sí' if row['doctor_recc_seasonal'] == 1 else 'No'}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Crear un gráfico de barras con tamaño ajustado\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "combinations.plot(kind='bar', x='combination', y='count', ax=ax, legend=False, color='tan')\n",
    "\n",
    "# Etiquetas y título del gráfico\n",
    "ax.set_xlabel('Combinaciones de Vacunación para gripe estacional y Recomendación')\n",
    "ax.set_ylabel('Número de Encuestados')\n",
    "ax.set_title('Número de Encuestados por Combinaciones de seasonal_vaccine y doctor_recc_seasonal')\n",
    "\n",
    "# Colocar los labels en diagonal con ajuste de alineación y tamaño de fuente\n",
    "plt.xticks(rotation=0, ha='center', fontsize=10)\n",
    "\n",
    "# Ajustar el diseño para que las etiquetas no se corten\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas con valores nulos\n",
    "columnas_con_nulos = merged_df.columns[merged_df.isnull().any()].tolist()\n",
    "\n",
    "nulos_por_columna = merged_df[columnas_con_nulos].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la gráfica\n",
    "plt.figure(figsize=(12, 8))\n",
    "nulos_por_columna.plot(kind='bar', color='skyblue')\n",
    "plt.title('Número de valores nulos por columna')\n",
    "plt.xlabel('Columnas')\n",
    "plt.ylabel('Número de valores nulos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellenar las columnas con valores nulos con la moda de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_moda_train:\n",
    "    moda = test[columna].mode()[0]\n",
    "    test[columna].fillna(moda, inplace=True)\n",
    "    print(f'{columna} - {moda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos KNNImputer para rellenar los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_knn_imputer_train:\n",
    "    imputer = KNNImputer(n_neighbors=num_neighbors_knn)\n",
    "    imputed_data = imputer.fit_transform(merged_df)\n",
    "    imputed_data = np.round(imputed_data).astype(int)\n",
    "    merged_df = pd.DataFrame(imputed_data, columns=merged_df.columns, index=merged_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delete_null_values_train:\n",
    "    rows_before = len(merged_df)  # Número de filas antes de eliminar valores faltantes\n",
    "\n",
    "    merged_df = merged_df.dropna()  # Eliminar filas con valores faltantes\n",
    "\n",
    "    rows_after = len(merged_df)  # Número de filas después de eliminar valores faltantes\n",
    "\n",
    "    print(\"Número de filas antes de eliminar valores faltantes:\", rows_before)\n",
    "    print(\"Número de filas después de eliminar valores faltantes:\", rows_after)\n",
    "    print(\"Número de filas eliminadas:\", rows_before - rows_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de características más importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la clase identificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop('respondent_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "\n",
    "y_h1n1_vaccine = merged_df['h1n1_vaccine']   # Primera columna objetivo (h1n1_vaccine)\n",
    "y_seasonal_vaccine = merged_df['seasonal_vaccine']   # Segunda columna objetivo (seasonal_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el selector de características para la primera columna objetivo\n",
    "selector_h1n1_vaccine = SelectKBest(score_func=f_classif, k=number_of_best_features)  # Aquí especificas el método de selección de características y el número de características que deseas seleccionar\n",
    "\n",
    "# Aplicar el selector a tus datos para la primera columna objetivo\n",
    "X_new_h1n1_vaccine = selector_h1n1_vaccine.fit_transform(X, y_h1n1_vaccine)\n",
    "\n",
    "# Obtener los índices de las características seleccionadas para la primera columna objetivo\n",
    "selected_features_h1n1_vaccine = selector_h1n1_vaccine.get_support(indices=True)\n",
    "\n",
    "# Obtener los nombres de las características seleccionadas para la primera columna objetivo\n",
    "selected_features_names_h1n1_vaccine = X.columns[selected_features_h1n1_vaccine]\n",
    "\n",
    "# Imprimir los nombres de las características seleccionadas para la primera columna objetivo\n",
    "print(\"Características seleccionadas para h1n1_vaccine:\", selected_features_names_h1n1_vaccine)\n",
    "\n",
    "# Obtener los pesos de cada característica para la primera columna objetivo\n",
    "feature_scores_h1n1_vaccine = selector_h1n1_vaccine.scores_\n",
    "\n",
    "# Crear un DataFrame con los nombres de las características y sus pesos para la primera columna objetivo\n",
    "feature_scores_df_h1n1_vaccine = pd.DataFrame({'Feature': X.columns, 'Score': feature_scores_h1n1_vaccine})\n",
    "\n",
    "# Ordenar el DataFrame por los pesos en orden descendente para la primera columna objetivo\n",
    "feature_scores_df_h1n1_vaccine = feature_scores_df_h1n1_vaccine.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Mostrar la gráfica de barras con los pesos de cada característica para la primera columna objetivo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_scores_df_h1n1_vaccine['Feature'], feature_scores_df_h1n1_vaccine['Score'], color='skyblue')\n",
    "plt.xlabel('Puntuación')\n",
    "plt.ylabel('Característica')\n",
    "plt.title('Puntuación de las características para H1N1_vaccine')\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el DataFrame ordenado por los pesos para la primera columna objetivo\n",
    "print(\"Puntuación de las características para H1N1_vaccine:\")\n",
    "print(feature_scores_df_h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el selector de características para la segunda columna objetivo\n",
    "selector_seasonal_vaccine = SelectKBest(score_func=f_classif, k=number_of_best_features)  # Aquí especificas el método de selección de características y el número de características que deseas seleccionar\n",
    "\n",
    "# Aplicar el selector a tus datos para la segunda columna objetivo\n",
    "X_new_seasonal_vaccine = selector_seasonal_vaccine.fit_transform(X, y_seasonal_vaccine)\n",
    "\n",
    "# Obtener los índices de las características seleccionadas para la segunda columna objetivo\n",
    "selected_features_seasonal_vaccine = selector_seasonal_vaccine.get_support(indices=True)\n",
    "\n",
    "# Obtener los nombres de las características seleccionadas para la segunda columna objetivo\n",
    "selected_features_names_seasonal_vaccine = X.columns[selected_features_seasonal_vaccine]\n",
    "\n",
    "# Imprimir los nombres de las características seleccionadas para la segunda columna objetivo\n",
    "print(\"Características seleccionadas para seasonal_vaccine:\", selected_features_names_seasonal_vaccine)\n",
    "\n",
    "# Obtener los pesos de cada característica para la segunda columna objetivo\n",
    "feature_scores_seasonal_vaccine = selector_seasonal_vaccine.scores_\n",
    "\n",
    "# Crear un DataFrame con los nombres de las características y sus pesos para la segunda columna objetivo\n",
    "feature_scores_df_seasonal_vaccine = pd.DataFrame({'Feature': X.columns, 'Score': feature_scores_seasonal_vaccine})\n",
    "\n",
    "# Ordenar el DataFrame por los pesos en orden descendente para la segunda columna objetivo\n",
    "feature_scores_df_seasonal_vaccine = feature_scores_df_seasonal_vaccine.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Mostrar la gráfica de barras con los pesos de cada característica para la segunda columna objetivo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_scores_df_seasonal_vaccine['Feature'], feature_scores_df_seasonal_vaccine['Score'], color='skyblue')\n",
    "plt.xlabel('Puntuación')\n",
    "plt.ylabel('Característica')\n",
    "plt.title('Puntuación de las características para seasonal_vaccine:')\n",
    "plt.show()\n",
    "\n",
    "# Imprimir el DataFrame ordenado por los pesos para la segunda columna objetivo\n",
    "print(\"Puntuación de las características para seasonal_vaccine:\")\n",
    "print(feature_scores_df_seasonal_vaccine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos métodos para el entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_y(X, y, top_features):\n",
    "    # Seleccionar las mejores características\n",
    "    X_mejores_caracteristicas = X[top_features]\n",
    "    \n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_mejores_caracteristicas, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if use_smote:\n",
    "        print(\"Aplicando SMOTE...\")\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "    if use_adasyn:\n",
    "        print(\"Aplicando ADASYN...\")\n",
    "        adasyn = ADASYN(random_state=42)\n",
    "        X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    if use_nearmiss:\n",
    "        print(\"Aplicando NearMiss...\")\n",
    "        nm = NearMiss(version=2)\n",
    "        X_train, y_train = nm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scaler(X):\n",
    "    \n",
    "    scaler = None\n",
    "    \n",
    "    if use_minmax_scaler:\n",
    "        print(\"Aplicando MinMaxScaler...\")\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "        X = pd.DataFrame(scaled_data, columns=X.columns)\n",
    "        \n",
    "    if use_standard_scaler:\n",
    "        print(\"Aplicando StandardScaler...\")\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "        X = pd.DataFrame(scaled_data, columns=X.columns)\n",
    "        \n",
    "    return X, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_y_evaluar(modelo, search_cv, X_train, X_test, y_train, y_test):\n",
    "    # Entrenar el modelo\n",
    "    search_cv.fit(X_train, y_train)\n",
    "    \n",
    "    print('¡Entrenamiento finalizado!')\n",
    "\n",
    "    # Obtener el mejor modelo entrenado\n",
    "    mejor_modelo = search_cv.best_estimator_\n",
    "\n",
    "    # Realizar predicciones\n",
    "    probabilities = mejor_modelo.predict_proba(X_test)[:, 1]\n",
    "    predictions = mejor_modelo.predict(X_test)\n",
    "\n",
    "    accuracy_result = accuracy_score(y_test, mejor_modelo.predict(X_test))\n",
    "    auc_result = roc_auc_score(y_test, probabilities, average='macro')\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_result)\n",
    "    print(\"AUC:\", auc_result)\n",
    "    \n",
    "    print(f'Mejores parámetros encontrados: {search_cv.best_params_}')\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    \n",
    "    # Graficar la curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f' Curva ROC - {modelo.__class__.__name__}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Graficar la matriz de confusión\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Matriz de confusión - {modelo.__class__.__name__}')\n",
    "    plt.show()\n",
    "    \n",
    "    return mejor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_y_evaluar_modelo_con_search(modelo, parametros, X, y, top_features, search_type):\n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = split_x_y(X, y, top_features)\n",
    "\n",
    "    # Crear el objeto de búsqueda\n",
    "    if search_type == 'grid':\n",
    "        print(f\"Empezando búsqueda de hiperpárametros para {modelo.__class__.__name__} con GridSearchCV\")\n",
    "        search_cv = GridSearchCV(estimator=modelo, param_grid=parametros, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    elif search_type == 'random':\n",
    "        print(f\"Empezando búsqueda de hiperpárametros para {modelo.__class__.__name__} con RandomSearchCV\")\n",
    "        search_cv = RandomizedSearchCV(estimator=modelo, param_distributions=parametros, scoring='roc_auc', cv=5, n_jobs=-1, n_iter=100)\n",
    "    else:\n",
    "        raise ValueError(\"search_type debe ser 'grid' o 'random'\")\n",
    "    \n",
    "    return entrenar_y_evaluar(modelo, search_cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluamos con LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, scaler = apply_scaler(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lazy_classifier(X, y, top_features, target):\n",
    "    print(f\"Evaluando modelos con LazyClassifier para {target}...\")\n",
    "    \n",
    "    lazy_classifier = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_x_y(X, y, top_features)\n",
    "    \n",
    "    models, predictions = lazy_classifier.fit(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_lazy_predict = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_lazy_predict:\n",
    "    predictions_h1n1_vaccine_lazypredict = evaluate_lazy_classifier(X, y_h1n1_vaccine, selected_features_names_h1n1_vaccine, 'h1n1_vaccine')\n",
    "\n",
    "    predictions_h1n1_vaccine_lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_lazy_predict:\n",
    "    predictions_seasonal_vaccine_lazypredict = evaluate_lazy_classifier(X, y_seasonal_vaccine, selected_features_names_seasonal_vaccine, 'seasonal_vaccine')\n",
    "\n",
    "    predictions_seasonal_vaccine_lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_h1n1_vaccine = None\n",
    "model_seasonal_vaccine = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_logistic_regression = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "    'max_iter': [100, 500, 1000, 2000],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'fit_intercept': [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h1n1_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if use_grid_search and use_logistic_regression_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con GridSearchCV y el modelo LogisticRegression...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        LogisticRegression(),\n",
    "        param_logistic_regression,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_logistic_regression_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con RandomSearchCV y el modelo LogisticRegression...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        LogisticRegression(),\n",
    "        param_logistic_regression,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seasonal_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_logistic_regression_seasonal_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con GridSearchCV y el modelo LogisticRegression...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        LogisticRegression(),\n",
    "        param_logistic_regression,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_logistic_regression_seasonal_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con RandomSearchCV y el modelo LogisticRegression...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        LogisticRegression(),\n",
    "        param_logistic_regression,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rf_classifier = {\"n_estimators\": [10, 50, 100],\n",
    "              \"max_depth\": [3, 5, 10, None],\n",
    "              \"max_features\": [1, 3, 5, 10],\n",
    "              \"min_samples_split\": [2, 5, 10],\n",
    "              \"bootstrap\": [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h1n1_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_random_forest_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con GridSearchCV y el modelo RandomForestClassifier...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_rf_classifier,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_random_forest_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con RandomSearchCV y el modelo RandomForestClassifier...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_rf_classifier,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seasonal_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_random_forest_seasonal_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con GridSearchCV y el modelo RandomForestClassifier...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_rf_classifier,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_random_forest_seasonal_vaccine:    \n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con RandomSearchCV y el modelo RandomForestClassifier...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_rf_classifier,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_adaboost_classifier = {\n",
    "    'n_estimators': [50, 100, 200, 500], \n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1, 10],  \n",
    "    'algorithm': ['SAMME', 'SAMME.R'],  \n",
    "    'random_state': [None, 0, 42, 100],  \n",
    "    'estimator': [None, DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=3)],  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h1n1_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_ada_boost_classifier_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con GridSearchCV y el modelo AdaBoostClassifier...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        AdaBoostClassifier(),\n",
    "        param_adaboost_classifier,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_ada_boost_classifier_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con RandomSearchCV y el modelo AdaBoostClassifier...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        AdaBoostClassifier(),\n",
    "        param_adaboost_classifier,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seasonal_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_ada_boost_classifier_seasonal_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con GridSearchCV y el modelo AdaBoostClassifier...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        AdaBoostClassifier(),\n",
    "        param_adaboost_classifier,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_ada_boost_classifier_seasonal_vaccine: \n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con RandomSearchCV y el modelo AdaBoostClassifier...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        AdaBoostClassifier(),\n",
    "        param_adaboost_classifier,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb_classifier = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h1n1_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_xgb_classifier_h1n1_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con GridSearchCV y el modelo XGBClassifier...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        XGBClassifier(),\n",
    "        param_xgb_classifier,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_xgb_classifier_h1n1_vaccine:    \n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para h1n1_vaccine con RandomSearchCV y el modelo XGBClassifier...\")\n",
    "    model_h1n1_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        XGBClassifier(),\n",
    "        param_xgb_classifier,\n",
    "        X,\n",
    "        y_h1n1_vaccine,\n",
    "        selected_features_names_h1n1_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seasonal_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_grid_search and use_xgb_classifier_seasonal_vaccine:\n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con GridSearchCV y el modelo XGBClassifier...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        XGBClassifier(),\n",
    "        param_xgb_classifier,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'grid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_random_search and use_xgb_classifier_seasonal_vaccine:      \n",
    "    print(\"Vamos a realizar búsqueda de hiperparámetros para seasonal_vaccine con RandomSearchCV y el modelo XGBClassifier...\")\n",
    "    model_seasonal_vaccine = entrenar_y_evaluar_modelo_con_search(\n",
    "        XGBClassifier(),\n",
    "        param_xgb_classifier,\n",
    "        X,\n",
    "        y_seasonal_vaccine,\n",
    "        selected_features_names_seasonal_vaccine,\n",
    "        'random'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_red_neuronal(X, y, top_features):\n",
    "    X_train, X_test, y_train, y_test = split_x_y(X, y, top_features)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(10,), kernel_regularizer=l2(0.01)),  # Capa densa con regularización L2\n",
    "        BatchNormalization(),  # Normalización de lotes\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # Capa densa con regularización L2\n",
    "        BatchNormalization(),  # Normalización de lotes\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),   # Capa densa con regularización L2\n",
    "        Dense(1, activation='sigmoid')  # Capa de salida con 1 neurona y función de activación sigmoide para clasificación binaria\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train, epochs=epochs_red_neuronal, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    probabilidades = model.predict(X_test)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, probabilidades, average='macro')\n",
    "\n",
    "    print(\"Área bajo la curva ROC (AUC):\", roc_auc)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h1n1_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_red_neuronal_h1n1_vaccine:\n",
    "    model_h1n1_vaccine = entrenar_red_neuronal(X, y_h1n1_vaccine, selected_features_names_h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seasonal_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_red_neuronal_seasonal_vaccine:\n",
    "    model_seasonal_vaccine = entrenar_red_neuronal(X, y_seasonal_vaccine, selected_features_names_seasonal_vaccine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizamos la predicción con el dataset de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos las columnas con el mismo encoder que se ha hecho en el dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, le in encoders.items():\n",
    "    if col in test.columns:\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificar columnas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_con_nulos = test.columns[test.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellenar las columnas con valores nulos con la moda de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_moda_test:\n",
    "    moda = test[columna].mode()[0]\n",
    "    test[columna].fillna(moda, inplace=True)\n",
    "    print(f'{columna} - {moda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellenamos los valores nulos con KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_knn_imputer_test:\n",
    "    imputer_test = KNNImputer(n_neighbors=5)\n",
    "    imputed_data_test = imputer.fit_transform(test)\n",
    "    imputed_data_test = np.round(imputed_data_test).astype(int)\n",
    "    test = pd.DataFrame(imputed_data_test, columns=test.columns, index=test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una copia de los datos de test para mantener los id de los encuestados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = test.copy()\n",
    "\n",
    "test = test.drop('respondent_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos los datos con el mismo scaler que se ha utilizado en los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not not_use_scaler:\n",
    "    test_scaled = scaler.transform(test)\n",
    "\n",
    "    test_df = pd.DataFrame(test_scaled, columns=test.columns)\n",
    "\n",
    "test_df = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la predicción para h1n1_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected_features_names_h1n1_vaccine = test_df[selected_features_names_h1n1_vaccine]\n",
    "\n",
    "probabilities_test_h1n1_vaccine = model_h1n1_vaccine.predict_proba(test_selected_features_names_h1n1_vaccine)[:, 1]\n",
    "\n",
    "probabilities_test_h1n1_vaccine_truncated = [round(prob, 1) for prob in probabilities_test_h1n1_vaccine]\n",
    "\n",
    "print(\"Probabilidades predichas para 'h1n1_vaccine' en el conjunto de prueba:\")\n",
    "print(probabilities_test_h1n1_vaccine_truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la predicción para seasonal_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected_features_names_seasonal_vaccine = test_df[selected_features_names_seasonal_vaccine]\n",
    "\n",
    "probabilities_test_seasonal_vaccine = model_seasonal_vaccine.predict_proba(test_selected_features_names_seasonal_vaccine)[:, 1] \n",
    "\n",
    "probabilities_test_seasonal_vaccine_truncated = [round(prob, 1) for prob in probabilities_test_seasonal_vaccine]\n",
    "\n",
    "print(\"Probabilidades predichas para 'seasonal_vaccine' en el conjunto de prueba:\")\n",
    "print(probabilities_test_seasonal_vaccine_truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezclamos la columna del encuestado con las probabilidades predichas de h1n1_vaccine y seasonal_vaccine en un mismo DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_ids = test_copy['respondent_id']\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'respondent_id': respondent_ids,\n",
    "    'h1n1_vaccine': probabilities_test_h1n1_vaccine,  # Probabilidades predichas para la primera variable objetivo (h1n1_vaccine)\n",
    "    'seasonal_vaccine': probabilities_test_seasonal_vaccine  # Probabilidades predichas para la segunda variable objetivo (seasonal_vaccine)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el archivo CSV para entregar en la competición añadiendo una marca de tiempo para identificarlos fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d\")\n",
    "time = now.strftime(\"%H-%M\")\n",
    "\n",
    "nombre_archivo = f'submissions/{date}/{time}/submission_{time}.csv'\n",
    "\n",
    "os.makedirs(os.path.dirname(nombre_archivo), exist_ok=True)\n",
    "\n",
    "submission_df.to_csv(nombre_archivo, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardamos los modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_h1n1_vaccine = f'submissions/{date}/{time}/h1n1_vaccine_model.pkl'\n",
    "\n",
    "location_seasonal_vaccine = f'submissions/{date}/{time}/seasonal_vaccine_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(location_h1n1_vaccine, 'wb') as f:\n",
    "    pickle.dump(model_h1n1_vaccine, f)\n",
    "    \n",
    "with open(location_seasonal_vaccine, 'wb') as f:\n",
    "    pickle.dump(model_seasonal_vaccine, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiempo total de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Tiempo total de ejecución: {execution_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
